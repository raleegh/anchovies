import inspect
import fnmatch
import uuid
import logging; logger = logging.getLogger(__name__)
from collections import deque, UserDict
from copy import copy
from types import MethodType
from typing import Iterator, Optional, Self, Sequence
from .exceptions import *
from .queues import *
from .tasks import Task


class IterTask(Task): 
    '''A task that runs a generator as the target function.'''
    def safe_iter(self, iterable): 
        '''Iterate within the Thread's start/stop scope.'''
        iterable = iter(iterable)
        while not self.stopped.wait(0): 
            try: 
                yield next(iterable)
            except StopIteration: 
                break

    def get_promise_constructor(self):
        target = self.finalize_consumer(self.target)
        kwds = self.kwds.copy()
        return (
            target,
            self.args, 
            kwds,
        ) 
    
    def finalize_consumer(self): 
        '''Wrap the consumer depending on if it is an iterator.'''
        if inspect.isgeneratorfunction(self.target) \
            or hasattr(self.target, '__iter__'): 
            def wrapper(*args, **kwds): 
                iterable = self.safe_iter(self.target(*args, **kwds))
                return deque(iterable, maxlen=1)
            return wrapper
        return self.target
    

class StreamingTask(Task):
    '''A task that has an underlying queue and runs IO.
    
    The target function can either be an iterator or callable.
    The target function must consume the provided `stream` arg
    entirely.

    Usage: 
    ```
    def consume(stream): 
        for x in stream:
            ...

    with StreamingTask(target=consume) as task: 
        task.put(1)
        ...
    ```
    '''
    def __init__(self, **kwds):
        super().__init__(**kwds)
        self.sinks: list[Self] = list()
        self.source: Optional[Self] = None

    def start_or_enter(self):
        self.queue: Queue = self.make_queue()
        return super().start_or_enter()
    
    def make_queue(self):
        '''Construct a Queue object.'''
        return self.also_promise(Queue())

    def get_promise_constructor(self):
        target, args, kwds = super().get_promise_constructor()
        kwds['stream'] = self
        return (
            target,
            args, 
            kwds,
        ) 
    
    def finalize_consumer(self): 
        '''Wrap the consumer depending on if it is an iterator.'''
        if inspect.isgeneratorfunction(self.target) \
            or hasattr(self.target, '__iter__'): 
            def wrapper(*args, **kwds): 
                iterable = self.safe_iter(self.target(*args, **kwds))
                if self.sinks: 
                    return self.multicast_to_sinks(iterable)
                return deque(iterable, maxlen=1)
            return wrapper
        return self.target

    def __iter__(self): 
        yield from self.queue

    def put(self, i): 
        '''Put to underlying queue.'''
        return self.queue.put(i)
    
    def get(self): 
        '''Get from underlying queue.'''
        return self.queue.get()
    
    def add_sink(self, sink: Self): 
        '''Associate a StreamingTask as a "sink".
        
        Everything generated by this will be forwarded 
        to all associated sinks.
        
        ```
        this = Task()
        this.add_sink(Sink1())
        this.add_sink(Sink2())
        ...
        This -- Sink1(This)
            \\
             Sink2(This)
        ```
        '''
        sink.source = self
        self.sinks.append(sink)
        self.also_promise(sink)

    def multicast_to_sinks(self, iterable: Iterator): 
        '''Provided an iterable, move everything to associated sinks.'''
        puts = tuple(sink.put for sink in self.sinks)
        for it in iterable: 
            for put in puts: 
                put(it)

    @property
    def has_checkin(self):
        return self.started.is_set()
    
    def checkin(self):
        logger.debug(f'{self} queue size -> {self.queue.qsize():,}')

    def copy(self): 
        '''Create a new instance of the stream.'''
        return copy(self)


class StreamStack:
    '''A "stack" of streams created by decoration.
    
    Streams can be stacked with decorators, and this 
    object keeps track of the chain of ownership.
    '''
    def __init__(self, stream: 'Stream'): 
        self.next: Optional[Stream] = None
        self.last: Optional[Stream] = None
        if isinstance(stream.target, Stream): 
            self.last = stream.target
            stream.target.stack.next = stream

    def innermost(self): 
        '''Return the innermost wrapped Stream.'''
        cur = self
        while cur.last: 
            cur = cur.last
        return cur
    
    def outermost(self): 
        '''Return the outermost wrapped Stream.'''
        cur = self
        while cur.next: 
            cur = cur.next
        return cur 
    
    def all(self): 
        '''Generate all sinks in the stack.'''
        cur = self.innermost()
        while cur.next: 
            yield cur.next
            cur = cur.next

    def all_sinks(self): 
        '''Generate all sinks excluding the current.'''
        for sink in self.all():
            if sink.last is None: 
                return
            yield sink

    def follow_downstream(self): 
        '''Using the Guide, trace the full path of this stream.'''
        seen = set()
        guide = self.outermost().guide
        for sink in self.all_sinks():
            upstream = guide.match(str(sink))
            upstream = tuple(upstream)
            for source in upstream:
                if not isinstance(source, SourceStream): 
                    continue
                if source not in seen: 
                    yield source
                    seen.add(source)
                for i in source.stack.follow_downstream(): 
                    if i not in seen: 
                        yield i 
                        seen.add(i)

    def is_start_of_stream_stack(self): 
        '''Tell if this node is a start.'''
        return len(self.follow_downstream()) == 1
    
    def follow_to_starts(self): 
        '''Return the "start" streams.'''
        for stream in self.follow_downstream(): 
            if stream.stack.is_start_of_stream_stack(): 
                yield stream


class Stream(StreamingTask):
    '''
    A stream is the base unit of the source/sink apparatus 
    which allows data routing between methods at runtime.

    The Stream API should not be interacted with directly, rather
    use the `@source/@sink` decorators.
    '''
    def __init__(self, tbl_wildcard: str, **kwds):
        super().__init__(**kwds)
        self.tbl_wildcard = tbl_wildcard
        self.stack = StreamStack(self)
        self.scheduled_by_sink: Optional[Self] = None
        self.included: set[Self] = set()
        self.guide: 'Optional[StreamGuide]' = None

    def __str__(self): 
        return self.tbl_wildcard

    def __repr__(self): 
        return '@source(%s)' % str(self.tbl_wildcard)
    
    @property
    def thread_label(self): 
        return repr(self)
    
    @property
    def sort_key(self): 
        '''Provide a method of sort for future prioritization feature.'''
        return self.tbl_wildcard
    
    def make_id(self):
        return str(uuid.uuid4())
    
    def __hash__(self): 
        return hash((str(self), self.id))
    
    def __eq__(self, other):
        if not isinstance(other, type(self)): 
            return False
        return (str(self), self.id) == (str(self), self.id)

    def __call__(self, *args, **kwds):
        return self.target(*args, **kwds)
    
    def add_sink(self, sink: Self):
        new_sink = sink.stack.outermost().copy()
        new_sink.scheduled_by_sink = sink
        return super().add_sink(new_sink)
    
    def find_sinks(self): 
        '''Find sinks in the graph to also execute.
        
        Based on the associated Guide, schedule streams
        for execution if they share a graph.
        '''
        sinks = self.guide.sinks.match(
            str(self),
            include=self.included,
        )
        for sink in sinks: 
            self.add_sink(sink)

    def finalize_consumer(self):
        func = super().finalize_consumer()
        def wrapper(*args, **kwds): 
            self.find_sinks()
            if self.source: 
                kwds['source'] = self.source
            if self.scheduled_by_sink: 
                kwds['sink'] = self.scheduled_by_sink
            from anchovies.sdk import runtime, session
            tbl = runtime().Tbl(self.tbl_wildcard)
            if tbl in session().datastore.tbl_store:
                tbl = session().datastore.tbl_store[tbl]
            kwds['tbl'] = tbl
            return func(*args, **kwds)
        return wrapper

    def include(self, seq: Sequence[Self]=()):
        '''Provide a list of streams to potentially schedule with this stream.
        
        Since streams form a Node graph, the streams provided here, if 
        in this Stream's path, will also be run.
        '''
        for maybe_include in seq: 
            if maybe_include is self: 
                continue
            path = set(maybe_include.stack.path())
            if self not in path: 
                continue
            self.included.add(maybe_include)

    def make_method(self, cls: type): 
        '''Convert the underlying function into a method 
        of the provided Class.
        '''
        func = self.stack.innermost().target
        return MethodType(func, cls)
    
    def run_singleton(self): 
        '''Utility method to run this stream on its own.'''
        return StreamingPlan((self,)).start_or_enter().join_or_exit()
    

class SourceStream(Stream): ...
class SinkStream(Stream):
    def __repr__(self):
        return '@sink(%s)' % str(self.tbl_wildcard)


class StreamGuide(UserDict): 
    '''
    A coordinator instance to help manage the execution of streams.
    
    All "@source" instances get key'd in via tbl/wildcard name, forcing uniqueness.
    Sinks do not need to be unique. Retrieve a @source in order to run it & it's ancestors.
    If you select all the @sources you want to run, and pass to `StreamingPlan`, the planner 
    will only run each node in the graph once.
    '''
    def __init__(self, operator: type): 
        super().__init__()
        self.operator = self.op = operator
        self.streams = list()
        self.sources = self.data
        for attr, stream in inspect.getmembers(self.op): 
            if isinstance(stream, Stream): 
                self.save_stream(stream, attr)
                for sink in stream.stack.all_sinks():
                    self.save_stream(sink)
        self.sinks = SinkGuide(self)

    def save_stream(self, stream: Stream, target_attribute: str=None): 
        '''Save a stream to the internal mechanism.'''
        x = stream
        if target_attribute:
            # we are scheduling on a class instance and 
            # need to convert the stream into a method. 
            setattr(self.op, target_attribute, x.make_method(self.op))
        x.guide = self
        self.streams.append(x)
        if isinstance(x, SourceStream): 
            self.sources[str(x)] = x

    def get(self, key) -> SourceStream: 
        '''Retrieve a guided stream.'''
        return super().get(key)
    
    def match(self, pat) -> Iterator[SourceStream]: 
        '''Glob pattern match streams contained by this Guide.'''
        if exact := self.get(pat):
            yield exact
            return
        for name, stream in self.copy().items(): 
            if (
                fnmatch.fnmatch(name, pat) 
                or fnmatch.fnmatch(pat, name)
            ) and stream is not exact:
                translation_tbl = str.maketrans('', '', '*?[]')
                if name != name.translate(translation_tbl):
                    # this means we matched a wildcard on the selection, so need to yield the name back out
                    new_stream = stream.clone(pat)
                    self.save_stream(new_stream)
                    yield new_stream
                    continue
                yield stream

    def select(self, selection) -> Sequence[Stream]: 
        '''Select from this guide a set of streams, with Glob pattern matching.'''
        res = set()
        for possible_match in selection: 
            for match in self.match(str(possible_match)): 
                res.add(match)
        return tuple(res)
    

class SinkGuide(UserDict): 
    '''A helper for the `StreamGuide` to collect `SinkStream`s.'''
    def __init__(self, guide: StreamGuide): 
        super().__init__()
        self.guide = guide
        sinks = list()
        for maybe_sink in self.guide.streams: 
            if not isinstance(maybe_sink, SinkStream): 
                continue
            sinks.append(maybe_sink)
        for sink in sinks: 
            for source in self.guide.match(str(self)): 
                self.map(source, sink)
    
    def map(self, source: SourceStream, sink: SinkStream): 
        if str(source) not in self: 
            self[str(source)] = list()
        self[str(source)].append(sink)

    def match(self, pat, *, include=None) -> Iterator[SinkStream]: 
        def yield_included(sinks): 
            for sink in sinks: 
                outer = sink.maybe_outer()
                if isinstance(outer, SinkStream): 
                    yield sink.clone() # always yield a fresh
                    continue
                    # always run sinks
                if include is not None and outer not in include: 
                    continue
                yield sink.clone() # always yield a fresh
        if exact := self.get(pat):
            yield from yield_included(exact)
        it = tuple(self.items())
        it = tuple(filter(
            lambda n: \
                (fnmatch.fnmatch(n[0], pat)
                    or fnmatch.fnmatch(pat, n[0])
                ) \
                and n[1] is not exact, 
            it
        ))
        for name, stream in it: 
            yield from yield_included(stream)

    def all(self): 
        for sinks in self.values(): 
            yield from sinks


class StreamingPlan(IterTask): 
    '''Run a sequence of streams via selection.'''
    def __init__(self, streams: Sequence[Stream]=()):
        self.streams = tuple(streams)
        super().__init__(target=self.plan_and_run_streams)
        self.seen = set()
        self.please_include = set()

    def __str__(self):
        return 'StreamingPlan+%s' % self.id
    
    def plan_and_run_streams(self): 
        '''Run selected streams.'''
        for stream in self.iter_streams(): 
            for start in stream.stack.follow_to_starts():
                start.include(self.please_include)
                self.also_promise(start)
                yield start
                start.join_or_exit()

    def iter_streams(self):
        '''Cycle through the selected streams.'''
        seen = self.seen = set()
        please_include = self.please_include = set()
        for stream in self.streams:
            please_include.update(set(stream.stack.follow_downstream()))
        for stream in sorted(self.streams, key=lambda s: s.sort_key): 
            if stream in seen: 
                continue
            yield stream
